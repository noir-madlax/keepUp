# æœ€ç»ˆæŠ€æœ¯æ–¹æ¡ˆ - GitHub Actions + Puppeteer

> âš ï¸ é‡è¦æ›´æ–°ï¼šæ”¾å¼ƒSupabase Edge Functionsæ–¹æ¡ˆï¼Œæ”¹ç”¨GitHub Actions  
> åŸå› ï¼šEdge Functionsæ— æ³•è¿è¡Œæµè§ˆå™¨ï¼Œå³ä½¿Playwright for Denoä¹Ÿéœ€è¦æµè§ˆå™¨äºŒè¿›åˆ¶æ–‡ä»¶

## ğŸ¯ æœ€ç»ˆæ–¹æ¡ˆæ¶æ„

### å®Œæ•´æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‰ç«¯ (Vue 3 + Vercel)                               â”‚
â”‚  - /monitor é¡µé¢å±•ç¤º                                 â”‚
â”‚  - æ‰‹åŠ¨è§¦å‘æŒ‰é’®                                       â”‚
â”‚  - å®æ—¶æ•°æ®å±•ç¤º                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ â‘  æ‰‹åŠ¨è§¦å‘ï¼šè°ƒç”¨GitHub API
              â”‚ â‘¡ æ•°æ®æŸ¥è¯¢ï¼šSupabase Client
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Actions (Workflows)       â”‚  â”‚ Supabase     â”‚
â”‚  å®šæ—¶ä»»åŠ¡: cron '0 1 * * *'      â”‚â†â”€â”¤ Database     â”‚
â”‚  æ‰‹åŠ¨è§¦å‘: workflow_dispatch     â”‚  â”‚ + Storage    â”‚
â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â†‘
â”‚  â”‚ scrape-openrouter.yml      â”‚ â”‚         â”‚
â”‚  â”‚ scrape-tikhub.yml          â”‚ â”‚         â”‚ POSTæ•°æ®
â”‚  â”‚ scrape-cursor.yml          â”‚ â”‚         â”‚
â”‚  â”‚ scrape-all.yml (ç»Ÿä¸€è°ƒåº¦)  â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                  â”‚
â”‚  æ¯ä¸ªworkflow:                   â”‚
â”‚  1. å®‰è£…Puppeteer               â”‚
â”‚  2. è¿è¡ŒæŠ“å–è„šæœ¬                â”‚
â”‚  3. ä¿å­˜æ•°æ®åˆ°Supabase          â”‚
â”‚  4. ä¸Šä¼ æˆªå›¾åˆ°Storage           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… ä¼˜åŠ¿è¯´æ˜

### ä¸ºä»€ä¹ˆé€‰æ‹©GitHub Actions

1. **å®Œå…¨å…è´¹**
   - 2000åˆ†é’Ÿ/æœˆï¼ˆå…¬å¼€ä»“åº“unlimitedï¼‰
   - è¿œè¶…Vercel(10ç§’)å’ŒSupabase(90ç§’)çš„é™åˆ¶

2. **é¢„è£…Chromeæµè§ˆå™¨**
   - ubuntu-latesté•œåƒè‡ªå¸¦Chrome/Chromium
   - æ— éœ€Dockerå®¹å™¨
   - æ— éœ€é¢å¤–é…ç½®

3. **æ— è¶…æ—¶é™åˆ¶**
   - å•ä¸ªjobæœ€å¤š6å°æ—¶
   - è¶³å¤Ÿè¿è¡Œä»»ä½•å¤æ‚çš„æŠ“å–ä»»åŠ¡

4. **ç¬¦åˆä½ çš„è¦æ±‚**
   - âœ… ä¸ç”¨Docker
   - âœ… å‰ç«¯Vercel
   - âœ… æ•°æ®åº“Supabase
   - âœ… çº¯ä»£ç é…ç½®ï¼ˆYAMLï¼‰

5. **æ˜“äºç»´æŠ¤**
   - Workflowæ–‡ä»¶å°±æ˜¯é…ç½®
   - å¯ä»¥ç‰ˆæœ¬æ§åˆ¶
   - æ”¯æŒsecretsç®¡ç†

## ğŸ“ é¡¹ç›®ç»“æ„

```
keepup-v2/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ scrape-openrouter.yml    # OpenRouteræŠ“å–
â”‚       â”œâ”€â”€ scrape-tikhub.yml        # TikHubæŠ“å–
â”‚       â”œâ”€â”€ scrape-cursor.yml        # CursoræŠ“å–
â”‚       â””â”€â”€ scrape-all.yml           # ç»Ÿä¸€è°ƒåº¦ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ engine.js                # é€šç”¨æŠ“å–å¼•æ“
â”‚   â”‚   â”œâ”€â”€ config-parser.js         # é…ç½®è§£æå™¨
â”‚   â”‚   â””â”€â”€ supabase-client.js       # Supabaseå®¢æˆ·ç«¯
â”‚   â”‚
â”‚   â”œâ”€â”€ scrape-openrouter.js         # OpenRouterè„šæœ¬
â”‚   â”œâ”€â”€ scrape-tikhub.js             # TikHubè„šæœ¬
â”‚   â”œâ”€â”€ scrape-cursor.js             # Cursorè„šæœ¬
â”‚   â””â”€â”€ package.json                 # ä¾èµ–é…ç½®
â”‚
â”œâ”€â”€ monitor-configs/                  # YAMLé…ç½®ï¼ˆå·²æœ‰ï¼‰
â”‚   â”œâ”€â”€ openrouter.yaml
â”‚   â”œâ”€â”€ tikhub.yaml
â”‚   â””â”€â”€ cursor.yaml
â”‚
â”œâ”€â”€ src/                              # å‰ç«¯ä»£ç ï¼ˆå·²æœ‰ï¼‰
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â””â”€â”€ MonitorView.vue
â”‚   â””â”€â”€ components/
â”‚       â””â”€â”€ MonitorCard.vue
â”‚
â””â”€â”€ api/                              # Vercel APIï¼ˆç”¨äºæ‰‹åŠ¨è§¦å‘ï¼‰
    â””â”€â”€ trigger-scrape.ts             # è§¦å‘GitHub Actions
```

## ğŸ”§ GitHub Actionsé…ç½®

### 1. é€šç”¨æŠ“å–workflowç¤ºä¾‹

```yaml
# .github/workflows/scrape-openrouter.yml
name: Scrape OpenRouter

on:
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
  
  # å¯è¢«å…¶ä»–workflowè°ƒç”¨
  workflow_call:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      # 1. æ£€å‡ºä»£ç 
      - name: Checkout code
        uses: actions/checkout@v3
      
      # 2. è®¾ç½®Node.jsç¯å¢ƒ
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: scripts/package-lock.json
      
      # 3. å®‰è£…ä¾èµ–ï¼ˆåŒ…æ‹¬Puppeteerï¼‰
      - name: Install dependencies
        run: |
          cd scripts
          npm ci
      
      # 4. è¿è¡ŒæŠ“å–è„šæœ¬
      - name: Run scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SITE_SLUG: openrouter
        run: |
          cd scripts
          node scrape-openrouter.js
      
      # 5. ä¸Šä¼ æˆªå›¾ï¼ˆå¤‡ä»½ï¼‰
      - name: Upload screenshots
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: screenshots-openrouter
          path: scripts/temp/*.png
          retention-days: 7
```

### 2. ç»Ÿä¸€è°ƒåº¦workflow

```yaml
# .github/workflows/scrape-all.yml
name: Daily Monitor All Sites

on:
  # å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©UTC 1:00ï¼ˆåŒ—äº¬æ—¶é—´9:00ï¼‰
  schedule:
    - cron: '0 1 * * *'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:

jobs:
  scrape-all:
    runs-on: ubuntu-latest
    strategy:
      # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç½‘ç«™
      matrix:
        site: [openrouter, tikhub, cursor]
      # å¤±è´¥åç»§ç»­å…¶ä»–ä»»åŠ¡
      fail-fast: false
    
    steps:
      - uses: actions/checkout@v3
      
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          cd scripts
          npm ci
      
      - name: Scrape ${{ matrix.site }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SITE_SLUG: ${{ matrix.site }}
        run: |
          cd scripts
          node scrape-${{ matrix.site }}.js
```

## ğŸ“ æŠ“å–è„šæœ¬å®ç°

### é€šç”¨æŠ“å–å¼•æ“ (scripts/scraper/engine.js)

```javascript
const puppeteer = require('puppeteer');
const fs = require('fs').promises;
const path = require('path');
const { createClient } = require('./supabase-client');

class ScraperEngine {
  constructor(config, cookies) {
    this.config = config;
    this.cookies = cookies;
    this.supabase = createClient();
  }

  async scrape() {
    const startTime = Date.now();
    let browser, page;
    
    try {
      // 1. å¯åŠ¨æµè§ˆå™¨
      browser = await puppeteer.launch({
        headless: 'new',
        args: [
          '--no-sandbox',
          '--disable-setuid-sandbox',
          '--disable-dev-shm-usage',
          '--disable-gpu'
        ]
      });

      page = await browser.newPage();
      
      // 2. è®¾ç½®viewportå’Œuser-agent
      await page.setViewport({ width: 1920, height: 1080 });
      await page.setUserAgent('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36');
      
      // 3. è®¾ç½®Cookie
      await page.setCookie(...this.normalizeCookies(this.cookies));
      
      // 4. æ‰§è¡Œé…ç½®æ­¥éª¤
      const data = {};
      let screenshotBuffer = null;
      
      for (const step of this.config.steps) {
        await this.executeStep(page, step, data);
      }
      
      // 5. éªŒè¯Cookieæœ‰æ•ˆæ€§
      const cookieValid = await this.validateCookie(page);
      
      // 6. ä¿å­˜ç»“æœ
      const result = {
        success: cookieValid,
        status: cookieValid ? 'success' : 'cookie_invalid',
        data: { ...data, scraped_at: new Date().toISOString() },
        duration: Date.now() - startTime,
        cookie_valid: cookieValid
      };
      
      // 7. ä¿å­˜åˆ°Supabase
      await this.saveToDatabase(result);
      
      return result;
      
    } catch (error) {
      console.error('Scrape error:', error);
      
      // ä¿å­˜é”™è¯¯è®°å½•
      await this.saveToDatabase({
        success: false,
        status: 'failed',
        error_message: error.message,
        duration: Date.now() - startTime
      });
      
      throw error;
      
    } finally {
      if (browser) {
        await browser.close();
      }
    }
  }

  async executeStep(page, step, data) {
    console.log(`Executing step: ${step.action}`);
    
    switch (step.action) {
      case 'navigate':
        await page.goto(step.url, {
          waitUntil: step.wait_for || 'networkidle2',
          timeout: step.timeout || 30000
        });
        break;
      
      case 'wait':
        await page.waitForSelector(step.selector, {
          timeout: step.timeout || 10000
        }).catch(() => {
          console.warn(`Element not found: ${step.selector}`);
        });
        break;
      
      case 'extract':
        const value = await this.extractData(page, step);
        data[step.name] = value;
        console.log(`Extracted ${step.name}:`, value);
        break;
      
      case 'screenshot':
        const screenshot = await page.screenshot({
          type: 'png',
          fullPage: step.full_page || false
        });
        
        // ä¿å­˜åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•
        const tempDir = path.join(__dirname, '..', 'temp');
        await fs.mkdir(tempDir, { recursive: true });
        const localPath = path.join(tempDir, `${this.config.name}.png`);
        await fs.writeFile(localPath, screenshot);
        
        // ä¸Šä¼ åˆ°Supabase Storage
        await this.uploadScreenshot(screenshot);
        break;
      
      case 'click':
        await page.click(step.selector);
        break;
      
      case 'type':
        await page.type(step.selector, step.value);
        break;
      
      default:
        console.warn(`Unknown action: ${step.action}`);
    }
  }

  async extractData(page, step) {
    const { selector, extract_type, regex_pattern, regex_group, transform } = step;
    
    let rawValue;
    
    try {
      if (extract_type === 'regex' || regex_pattern) {
        // æ­£åˆ™æå–
        const bodyText = await page.evaluate(() => document.body.innerText);
        const pattern = new RegExp(regex_pattern || selector.replace('text=/', '').replace('/', ''));
        const match = bodyText.match(pattern);
        rawValue = match && match[regex_group || 1] ? match[regex_group || 1] : null;
      } else {
        // CSSé€‰æ‹©å™¨æå–
        rawValue = await page.$eval(selector, el => el.textContent).catch(() => null);
      }
      
      // æ•°æ®è½¬æ¢
      if (rawValue && transform) {
        switch (transform) {
          case 'float':
            return parseFloat(rawValue);
          case 'int':
            return parseInt(rawValue, 10);
          case 'date':
            return new Date(rawValue).toISOString();
          default:
            return rawValue;
        }
      }
      
      return rawValue;
      
    } catch (error) {
      console.error(`Extract error for ${step.name}:`, error);
      return null;
    }
  }

  async validateCookie(page) {
    if (!this.config.validation || !this.config.validation.cookie_check) {
      return true; // æ²¡æœ‰é…ç½®éªŒè¯è§„åˆ™ï¼Œé»˜è®¤æœ‰æ•ˆ
    }
    
    const { selector, should_exist = true } = this.config.validation.cookie_check;
    
    try {
      const elementCount = await page.$$eval(selector, els => els.length);
      const exists = elementCount > 0;
      return exists === should_exist;
    } catch (error) {
      console.warn('Cookie validation failed:', error);
      return false;
    }
  }

  async uploadScreenshot(buffer) {
    const siteSlug = this.config.name.toLowerCase().replace(/\s+/g, '-');
    const filename = `${siteSlug}/latest.png`;
    
    const { error } = await this.supabase.storage
      .from('monitor-screenshots')
      .upload(filename, buffer, {
        contentType: 'image/png',
        upsert: true
      });
    
    if (error) {
      console.error('Screenshot upload error:', error);
    } else {
      console.log('Screenshot uploaded:', filename);
    }
  }

  async saveToDatabase(result) {
    const siteSlug = this.config.name.toLowerCase().replace(/\s+/g, '-');
    
    // ä¿å­˜è®°å½•
    const { error: recordError } = await this.supabase
      .from('keep_monitor_records')
      .insert({
        site_slug: siteSlug,
        data: result.data || {},
        screenshot_url: result.success ? `monitor-screenshots/${siteSlug}/latest.png` : null,
        scrape_duration: result.duration,
        status: result.status,
        error_message: result.error_message || null,
        trigger_source: 'auto'
      });
    
    if (recordError) {
      console.error('Database save error:', recordError);
    }
    
    // æ›´æ–°CookieçŠ¶æ€
    const { error: cookieError } = await this.supabase
      .from('keep_monitor_cookies')
      .update({
        is_valid: result.cookie_valid !== false,
        last_validated_at: new Date().toISOString(),
        validation_error: result.error_message || null
      })
      .eq('site_slug', siteSlug);
    
    if (cookieError) {
      console.error('Cookie update error:', cookieError);
    }
  }

  normalizeCookies(cookies) {
    return cookies.map(c => ({
      name: c.name,
      value: c.value,
      domain: c.domain,
      path: c.path || '/',
      expires: c.expirationDate,
      httpOnly: c.httpOnly || false,
      secure: c.secure || false,
      sameSite: c.sameSite === 'unspecified' ? 'lax' : c.sameSite
    }));
  }
}

module.exports = ScraperEngine;
```

### å…·ä½“ç½‘ç«™è„šæœ¬ç¤ºä¾‹ (scripts/scrape-openrouter.js)

```javascript
const yaml = require('js-yaml');
const fs = require('fs').promises;
const path = require('path');
const ScraperEngine = require('./scraper/engine');
const { createClient } = require('./scraper/supabase-client');

async function main() {
  try {
    console.log('Starting OpenRouter scraper...');
    
    const supabase = createClient();
    
    // 1. ä»æ•°æ®åº“è·å–é…ç½®å’ŒCookie
    const { data: site } = await supabase
      .from('keep_monitor_sites')
      .select('*')
      .eq('slug', 'openrouter')
      .single();
    
    const { data: cookieData } = await supabase
      .from('keep_monitor_cookies')
      .select('*')
      .eq('site_slug', 'openrouter')
      .single();
    
    if (!site || !cookieData) {
      throw new Error('Site or cookie data not found');
    }
    
    // 2. åˆ›å»ºæŠ“å–å¼•æ“
    const engine = new ScraperEngine(
      site.scraper_config,
      cookieData.cookies
    );
    
    // 3. æ‰§è¡ŒæŠ“å–
    const result = await engine.scrape();
    
    console.log('Scrape completed:', result);
    process.exit(result.success ? 0 : 1);
    
  } catch (error) {
    console.error('Fatal error:', error);
    process.exit(1);
  }
}

main();
```

## ğŸ” GitHub Secretsé…ç½®

åœ¨GitHubä»“åº“Settings â†’ Secrets and variables â†’ Actionsä¸­æ·»åŠ ï¼š

```
SUPABASE_URL = https://ojbocxqvufoblihkzijn.supabase.co
SUPABASE_SERVICE_ROLE_KEY = your-service-role-key
```

## ğŸ® å‰ç«¯æ‰‹åŠ¨è§¦å‘

### API Route (api/trigger-scrape.ts)

```typescript
import type { VercelRequest, VercelResponse } from '@vercel/node';

export default async function handler(
  req: VercelRequest,
  res: VercelResponse
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { site_slug } = req.body;
  
  if (!site_slug) {
    return res.status(400).json({ error: 'Missing site_slug' });
  }

  try {
    // è§¦å‘GitHub Actions workflow
    const response = await fetch(
      `https://api.github.com/repos/${process.env.GITHUB_REPO}/actions/workflows/scrape-${site_slug}.yml/dispatches`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          ref: 'main'
        })
      }
    );

    if (!response.ok) {
      throw new Error(`GitHub API error: ${response.statusText}`);
    }

    return res.status(200).json({
      success: true,
      message: `Triggered scrape for ${site_slug}`
    });

  } catch (error) {
    console.error('Trigger error:', error);
    return res.status(500).json({
      success: false,
      error: error.message
    });
  }
}
```

## âœ… æ–¹æ¡ˆä¼˜åŠ¿æ€»ç»“

1. **å®Œå…¨ç¬¦åˆéœ€æ±‚**
   - âœ… æ— éœ€Docker
   - âœ… å‰ç«¯Vercel
   - âœ… æ•°æ®åº“Supabase
   - âœ… é…ç½®åŒ–YAML

2. **æˆæœ¬ä¼˜åŠ¿**
   - âœ… å®Œå…¨å…è´¹ï¼ˆå…¬å¼€ä»“åº“ï¼‰
   - âœ… æ— éœ€ä»˜è´¹çš„æµè§ˆå™¨æœåŠ¡

3. **æ˜“äºç»´æŠ¤**
   - âœ… Workflowå³é…ç½®
   - âœ… ç‰ˆæœ¬æ§åˆ¶
   - âœ… å¯è§†åŒ–æ‰§è¡Œæ—¥å¿—

4. **æ€§èƒ½ä¼˜åŠ¿**
   - âœ… æ— è¶…æ—¶é™åˆ¶
   - âœ… é¢„è£…Chrome
   - âœ… å¹¶è¡Œæ‰§è¡Œ

## ğŸ”„ è¿ç§»æ­¥éª¤

1. åˆ é™¤`supabase/functions/`ç›¸å…³ä»£ç 
2. åˆ›å»º`.github/workflows/`ç›®å½•
3. åˆ›å»º`scripts/`ç›®å½•å’ŒæŠ“å–è„šæœ¬
4. é…ç½®GitHub Secrets
5. æµ‹è¯•æ‰‹åŠ¨è§¦å‘workflow
6. ç­‰å¾…å®šæ—¶ä»»åŠ¡è‡ªåŠ¨æ‰§è¡Œ

è¿™ä¸ªæ–¹æ¡ˆå®Œå…¨æ»¡è¶³æ‚¨çš„è¦æ±‚ï¼šçº¯å‰ç«¯Vercel + Supabaseï¼Œæ— Dockerï¼Œé…ç½®åŒ–æ“ä½œï¼

